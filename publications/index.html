<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Clément Elvira | publications</title>
  <meta name="description" content="Personal webpage of Clément Elvira. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Clément</strong> Elvira
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a>-->

        <!-- Pages -->
        
          
        
          
        
          
            <a class="page-link" href="/projects/">projects</a>
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <a class="page-link" href="/vita/">vita</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Publications by categories in reversed  chronological order. (last update march 2022)</h5>
  </header>

  <article class="post-content publications clearfix">
    <h4 id="preprints">Preprint(s)</h4>
<ol class="bibliography"><li>

<div id="elvira2021safeSLOPE">
  
    <span class="title">Safe rules for the identification of zeros in the solutions of the SLOPE problem,
			author=Elvira, Clément and Herzet, Cédric</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2021slope/elvira2021SLOPEsuppmat.pdf" target="_blank">supplementary material</a>]
  
  
  
    [<a href="http://arxiv.org/abs/2110.11784" target="_blank">arXiv</a>]
  
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2021slope/elvira2021SLOPE.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03400322" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://gitlab-research.centralesupelec.fr/2020elvirac/slope-screening" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@preprint{elvira2021safeSLOPE,
  title = {{Safe rules for the identification of zeros in the solutions of the SLOPE problem},
  			author={Elvira, Clément and Herzet, Cédric}},
  year = {2021},
  arxiv = {2110.11784},
  month = oct,
  pdf = {../../pdf/articles/elvira2021slope/elvira2021SLOPE.pdf},
  hal = {https://hal.archives-ouvertes.fr/hal-03400322},
  code = {https://gitlab-research.centralesupelec.fr/2020elvirac/slope-screening},
  suppmat = {../../pdf/articles/elvira2021slope/elvira2021SLOPEsuppmat.pdf}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2017preprint">
  
    <span class="title">Bayesian nonparametric principal component analysis</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://dobigeon.perso.enseeiht.fr/" target="_blank">Dobigeon, Nicolas</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2017
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="http://arxiv.org/abs/1709.05667" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01687236/" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@preprint{elvira2017preprint,
  title = {Bayesian nonparametric principal component analysis},
  author = {Elvira, Cl{\'e}ment and Chainais, Pierre and Dobigeon, Nicolas},
  journal = {arXiv preprint arXiv:1709.05667},
  year = {2017},
  arxiv = {1709.05667},
  hal = {https://hal.archives-ouvertes.fr/hal-01687236/}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Principal component analysis (PCA) is very popular to perform dimension reduction. The selection of the number of significant components is essential but often based on some practical heuristics depending on the application. Only few works have proposed a probabilistic approach able to infer the number of significant components. To this purpose, this paper introduces a Bayesian nonparametric principal component analysis (BNP-PCA). The proposed model projects observations onto a random orthogonal basis which is assigned a prior distribution defined on the Stiefel manifold. The prior on factor scores involves an Indian buffet process to model the uncertainty related to the number of components. The parameters of interest as well as the nuisance parameters are finally inferred within a fully Bayesian framework via Monte Carlo sampling. A study of the (in-)consistence of the marginal maximum a posteriori estimator of the latent dimension is carried out. A new estimator of the subspace dimension is proposed. Moreover, for sake of statistical significance, a Kolmogorov-Smirnov test based on the posterior distribution of the principal components is used to refine this estimate. The behaviour of the algorithm is first studied on various synthetic examples. Finally, the proposed BNP dimension reduction approach is shown to be easily yet efficiently coupled with clustering or latent factor models within a unique framework.</p>
  </span>
  
</div>
</li></ol>

<h4 id="international-journal-papers">International journal papers</h4>
<ol class="bibliography"><li>

<div id="elvira2021">
  
    <span class="title">When does OMP achieve exact recovery with continuous dictionaries?</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a>, 
              
            
          
        
      
        
          
            
              
                <a href="http://webpages.lss.supelec.fr/perso/charles.soussen/soussen_EN.html" target="_blank">Soussen, Charles</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Applied and Computational Harmonic Analysis</em>
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1016/j.acha.2020.12.002" target="_blank">DOI</a>]
  
  
    [<a href="http://arxiv.org/abs/1904.06311" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://hal.inria.fr/hal-02099464v4" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@article{elvira2021,
  title = {When does OMP achieve exact recovery with continuous dictionaries?},
  author = {Elvira, Cl{\'e}ment and Gribonval, R{\'e}mi and Soussen, Charles and Herzet, Cédric},
  journal = {Applied and Computational Harmonic Analysis},
  volume = {51},
  pages = {374 - 413},
  year = {2021},
  issn = {1063-5203},
  doi = {10.1016/j.acha.2020.12.002},
  url = {http://www.sciencedirect.com/science/article/pii/S1063520320300841},
  arxiv = {1904.06311},
  hal = {https://hal.inria.fr/hal-02099464v4}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>This paper presents new theoretical results on sparse recovery guarantees for a greedy algorithm, Orthogonal Matching Pursuit (OMP), in the context of continuous parametric dictionaries. Here, the continuous setting means that the dictionary is made up of an infinite (potentially uncountable) number of atoms. In this work, we rely on the Hilbert structure of the observation space to express our recovery results as a property of the kernel defined by the inner product between two atoms. Using a continuous extension of Tropp’s Exact Recovery Condition, we identify two key notions of admissible kernel and admissible support that are sufficient to ensure exact recovery with OMP. We exhibit a family of admissible kernels relying on completely monotone functions for which admissibility holds for any support in the one-dimensional setting. For higher dimensional parameter spaces, an additional notion of axis admissibility is shown to be sufficient to ensure a form of delayed recovery. An additional algebraic condition involving a finite subset of (known) atoms further yields exact recovery guarantees. Finally, a coherence-based viewpoint on these results provides recovery guarantees in terms of a minimum separation assumption.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2020_TSP">
  
    <span class="title">Safe Squeezing for Antisparse Coding</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cedric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Signal Processing</em>
    
    
      2020
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1109/tsp.2020.2995192" target="_blank">DOI</a>]
  
  
    [<a href="http://arxiv.org/abs/1911.07508" target="_blank">arXiv</a>]
  
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2020_TSP.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02368134" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://gitlab.inria.fr/celvira/safe-squeezing" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@article{elvira2020_TSP,
  title = {{Safe Squeezing for Antisparse Coding}},
  author = {Elvira, Cl{\'e}ment and Herzet, Cedric},
  hal = {https://hal.archives-ouvertes.fr/hal-02368134},
  year = {2020},
  arxiv = {1911.07508},
  doi = {10.1109/tsp.2020.2995192},
  url = {https://doi.org/10.1109/tsp.2020.2995192},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  journal = {{IEEE} Transactions on Signal Processing},
  keywords = {antisparse coding ; safe screening ; scaled projected-gradient algorithm ; Frank-Wolfe algorithm},
  pdf = {../../pdf/articles/elvira2020_TSP.pdf},
  hal_id = {hal-02368134},
  hal_version = {v1},
  code = {https://gitlab.inria.fr/celvira/safe-squeezing}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Spreading the information over all coefficients of a representation is a desirable property in many applications such as digital communication or machine learning. This so-called antisparse representation can be obtained by solving a convex program involving an l_∞-norm penalty combined with a quadratic discrepancy. In this paper, we propose a new methodology , dubbed safe squeezing, to accelerate the computation of antisparse representation. We describe a test that allows to detect saturated entries in the solution of the optimization problem. The contribution of these entries is compacted into a single vector, thus operating a form of dimensionality reduction. We propose two algorithms to solve the resulting lower dimensional problem. Numerical experiments show the effectiveness of the proposed method to detect the saturated components of the solution and illustrates the induced computational gains in the resolution of the antisparse problem.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2017_TSP">
  
    <span class="title">Bayesian Antisparse Coding</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://dobigeon.perso.enseeiht.fr/" target="_blank">Dobigeon, Nicolas</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Signal Processing</em>
    
    
      2017
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1109/TSP.2016.2645543" target="_blank">DOI</a>]
  
  
    [<a href="http://arxiv.org/abs/https://arxiv.org/abs/1512.06086" target="_blank">arXiv</a>]
  
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2017_TSP.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01433706" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://github.com/c-elvira/bayesian_antisparse_algorithm" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@article{elvira2017_TSP,
  author = {Elvira, Clément and Chainais, Pierre and Dobigeon, Nicolas},
  journal = {IEEE Transactions on Signal Processing},
  title = {Bayesian Antisparse Coding},
  year = {2017},
  volume = {65},
  number = {7},
  pages = {1660-1672},
  keywords = {Bayes methods;Gaussian distribution;Markov processes;Monte Carlo methods;encoding;inverse problems;maximum likelihood estimation;mean square error methods;ℓ∞-norm penalty;Bayesian antisparse coding;Gaussian linear model;Markov chain Monte Carlo algorithm;antisparse regularization;image processing;inverse problem;log-posterior distribution;maximum a posteriori estimator;minimum mean square error estimator;posterior distribution;probability distribution;signal processing;sparse representation;standard Gibbs sampler;Approximation algorithms;Bayes methods;Encoding;Image coding;Monte Carlo methods;Signal processing algorithms;Standards;Democratic distribution;anti-sparse representation;proximal operator},
  doi = {10.1109/TSP.2016.2645543},
  issn = {1053-587X},
  month = apr,
  pdf = {../../pdf/articles/elvira2017_TSP.pdf},
  arxiv = {https://arxiv.org/abs/1512.06086},
  hal = {https://hal.archives-ouvertes.fr/hal-01433706},
  code = {https://github.com/c-elvira/bayesian_antisparse_algorithm}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Sparse representations have proven their efficiency in solving a wide class of inverse problems encountered in signal and image processing. Conversely, enforcing the information to be spread uniformly over representation coefficients exhibits relevant properties in various applications such as robust encoding in digital communications. Antisparse regularization can be naturally expressed through an ℓ∞-norm penalty. This paper derives a probabilistic formulation of such representations. Anew probability distribution, referred to as the democratic prior, is first introduced. Its main properties as well as three random variate generators for this distribution are derived. Then this probability distribution is used as a prior to promote antisparsity in a Gaussian linear model, yielding a fully Bayesian formulation of antisparse coding. Two Markov chain Monte Carlo algorithms are proposed to generate samples according to the posterior distribution. The first one is a standard Gibbs sampler. The second one uses Metropolis-Hastings moves that exploit the proximity mapping of the log-posterior distribution. These samples are used to approximate maximum aposteriori and minimum mean square error estimators of both parameters and hyperparameters. Simulations on synthetic data illustrate the performances of the two proposed samplers, for both complete and over-complete dictionaries. All results are compared to the recent deterministic variational FITRA algorithm.</p>
  </span>
  
</div>
</li></ol>

<h4 id="international-conference-papers">International conference papers</h4>
<ol class="bibliography"><li>

<div id="elvira2020_itwist">
  
    <span class="title">Continuous dictionaries meet low-rank tensor approximations</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://jeremy-e-cohen.jimdofree.com/" target="_blank">Cohen, Jérémy E</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In iTwist 2020 - International Traveling Workshop on Interactions between low-complexity data models and Sensing Techniques</em>
    
    
      2020
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/workshop/elvira2020_itwist.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02567115/file/itwist20_paper.pdf" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2020_itwist,
  title = {{Continuous dictionaries meet low-rank tensor approximations}},
  author = {Elvira, Cl{\'e}ment and Cohen, J{\'e}r{\'e}my E and Herzet, C{\'e}dric and Gribonval, R{\'e}mi},
  url = {https://hal.archives-ouvertes.fr/hal-02567115},
  booktitle = {{iTwist 2020 - International Traveling Workshop on Interactions between low-complexity data models and Sensing Techniques}},
  address = {Nantes, France},
  pages = {1-3},
  year = {2020},
  month = jun,
  hal = {https://hal.archives-ouvertes.fr/hal-02567115/file/itwist20_paper.pdf},
  pdf = {../../pdf/workshop/elvira2020_itwist.pdf}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2020icassp2">
  
    <span class="title">BLASTER: An Off-Grid Method for Blind and Regularized\{Acoustic Echoes Retrieval</span>
    <span class="author">
      
        
          
            
              
                <a href="http://diegodicarlo.com/" target="_blank">Di Carlo, Diego</a>, 
              
            
          
        
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://members.loria.fr/ADeleforge/" target="_blank">Deleforge, Antoine</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://scholar.google.fr/citations?user=6BxpGj4AAAAJ&amp;hl=fr" target="_blank">Bertin, Nancy</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In accepted at IEEE ICASSP</em>
    
    
      2020
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
    [<a href="https://doi.org\10.1109/ICASSP40776.2020.9054647" target="_blank">DOI</a>]
  
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02469901" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://gitlab.inria.fr/panama-team/blaster" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2020icassp2,
  title = {{BLASTER: An Off-Grid Method for Blind and Regularized\\ Acoustic Echoes Retrieval}},
  author = {Di Carlo, Diego and Elvira, Cl{\'e}ment and Deleforge, Antoine and Bertin, Nancy and Gribonval, Rémi},
  booktitle = {accepted at IEEE ICASSP},
  publisher = {{IEEE}},
  year = {2020},
  doi = {10.1109/ICASSP40776.2020.9054647},
  code = {https://gitlab.inria.fr/panama-team/blaster},
  hal = {https://hal.archives-ouvertes.fr/hal-02469901}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2020icassp">
  
    <span class="title">Short and squeezed: accelerating the computation of antisparse representations with safe squeezing</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In accepted at IEEE ICASSP</em>
    
    
      2020
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
    [<a href="https://doi.org\10.1109/ICASSP40776.2020.9053156" target="_blank">DOI</a>]
  
  
  
  
  
  
  
  
  
    [<a href="https://gitlab.inria.fr/celvira/safe-squeezing" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2020icassp,
  title = {{Short and squeezed: accelerating the computation of antisparse representations with safe squeezing}},
  author = {Elvira, Cl{\'e}ment and Herzet, Cédric},
  booktitle = {accepted at IEEE ICASSP},
  publisher = {{IEEE}},
  year = {2020},
  code = {https://gitlab.inria.fr/celvira/safe-squeezing},
  doi = {10.1109/ICASSP40776.2020.9053156}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2019spars">
  
    <span class="title">Uniform k-step recovery with CMF dictionaries</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://webpages.lss.supelec.fr/perso/charles.soussen/soussen_EN.html" target="_blank">Soussen, Charles</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In SPARS 2019 - Signal Processing with Adaptive Sparse Structured Representations</em>
    
    
      2019
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
    [<a href="https://hal.inria.fr/hal-02157561/file/spars.pdf" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2019spars,
  title = {{Uniform k-step recovery with CMF dictionaries}},
  author = {Elvira, Cl{\'e}ment and Gribonval, R{\'e}mi and Herzet, C{\'e}dric and Soussen, Charles},
  url = {https://hal.inria.fr/hal-02157561},
  booktitle = {{SPARS 2019 - Signal Processing with Adaptive Sparse Structured Representations}},
  address = {Toulouse, France},
  pages = {1-2},
  year = {2019},
  month = jul,
  hal = {https://hal.inria.fr/hal-02157561/file/spars.pdf}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>We present new theoretical results on sparse recovery guarantees for a greedy algorithm, orthogonal matching pursuit (OMP), in the context of continuous parametric dictionaries, i.e., made up of an infinite uncountable number of atoms. We build up a family of dictionaries for which k-step recovery is possible.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2019icassp">
  
    <span class="title">OMP and continuous dictionaries: is k-step recovery possible?</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a>, 
              
            
          
        
      
        
          
            
              
                <a href="http://webpages.lss.supelec.fr/perso/charles.soussen/soussen_EN.html" target="_blank">Soussen, Charles</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>
    
    
      2019
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1109/ICASSP.2019.8683617" target="_blank">DOI</a>]
  
  
  
  
    [<a href="/assets/pdf/../../pdf/conferences/elvira2019icassp.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-02049486/file/icassp.pdf" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2019icassp,
  title = {{OMP and continuous dictionaries: is k-step recovery possible?}},
  author = {Elvira, Cl{\'e}ment and Gribonval, R{\'e}mi and Soussen, Charles and Herzet, Cédric},
  url = {https://hal.archives-ouvertes.fr/hal-02049486},
  booktitle = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  address = {Brighton, United Kingdom},
  organization = {{IEEE}},
  publisher = {{IEEE}},
  doi = {10.1109/ICASSP.2019.8683617},
  issn = {2379-190X},
  year = {2019},
  pages = {5546-5550},
  month = may,
  keywords = {Index Terms-Sparse representation ; exact recovery ; orthogonal matching pursuit ; continuous dictionaries ; sparse representation ; continuous dictio-naries},
  hal = {https://hal.archives-ouvertes.fr/hal-02049486/file/icassp.pdf},
  pdf = {../../pdf/conferences/elvira2019icassp.pdf}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>In this work, we present new theoretical results on sparse recovery guarantees for a greedy algorithm, orthogonal matching pursuit (OMP), in the context of continuous parametric dictionaries, i.e., made up of an infinite uncountable number of atoms.We build up a family of dictionaries for which k-step recovery is possible with OMP for 1-dimensional parameters. In higher dimension, algebraic conditions become necessary and will lead us to revisit some well-known k-step discrete analyses. Finally, a toy-example illustrates the level of tightness of our sufficient conditions.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2018CS">
  
    <span class="title">A case of exact recovery with OMP using continuous dictionaries</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://webpages.lss.supelec.fr/perso/charles.soussen/soussen_EN.html" target="_blank">Soussen, Charles</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In CS 2018 - 9th International Conference on Curves and Surfaces</em>
    
    
      2018
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
    [<a href="https://hal.inria.fr/hal-01937532" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2018CS,
  title = {{A case of exact recovery with OMP using continuous dictionaries}},
  author = {Elvira, Cl{\'e}ment and Gribonval, R{\'e}mi and Herzet, Cédric and Soussen, Charles},
  booktitle = {{CS 2018 - 9th International Conference on Curves and Surfaces}},
  address = {Arcachon, France},
  year = {2018},
  month = jun,
  hal = {https://hal.inria.fr/hal-01937532}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>We present new theoretical results on sparse recovery guarantees for a greedy algorithm, orthogonal matching pursuit (OMP), in the context of continuous dictionaries. Consider a sparse linear combination of atoms from a dictionary parameterized by some real parameters, for example, a combination of shifted versions of a basic waveform as in the context of sparse spike deconvolution. Currently, performance guarantees for greedy algorithms are typically carried out in the discrete setting associated to a grid of atom parameters, and based on, e.g., the coherence of the considered discretized dictionary \cite{tropp2004}. However, such analyses fail to be conclusive for grid-based approaches when the discretization step tends to zero, as the coherence goes to one. Instead, our analysis is directly conducted in the continuous setting. For atoms parametrized by a real parameter that are elements of the (infinite-dimensional) Hilbert space L_2(\mathbb{R}) of square integrable real functions, and such that the inner product between two atoms is the exponential of the negative absolute difference of the corresponding parameters, we show in the noise-free setting that OMP exactly recovers the atom parameters as well as their amplitudes, regardless of the number of distinct atoms. We exhibit a convolutive dictionary of exponentially decaying pulses for which the atoms have an analytic definition while their pairwise inner products have the prescribed form. The established guarantees rely on a proof technique which is the continuous equivalent of Tropp’s Exact Recovery Condition (ERC) \cite{tropp2004}. The proof exploits specific properties of the positive definite kernel between atom parameters defined by the inner product between the corresponding atoms. Future work will aim at characterizing the class of kernels for which such an analysis holds –in particular for higher dimensional parameters– and the compatibility of the guarantees with dimension reduction techniques such as sketching, which would pave the way to provably good greedy algorithms for compressive statistical learning \cite{Gribonval2017}. In light of the existing links between Tropp’s ERC and recovery guarantees for \ell_1 minimization \cite{tropp2006}, an interesting question is whether these guarantees extend to sparse spike recovery with total variation norm minimization \cite{Duval2015,candes2014}.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2018eusipco">
  
    <span class="title">Small variance asymptotics and bayesian nonparametrics for dictionary learning</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clement</em>,
            
          
        
      
        
          
            
              
                <a href="https://hphuongdang.github.io/" target="_blank">Dang, Hong-Phuong</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2018 26th European Signal Processing Conference (EUSIPCO)</em>
    
    
      2018
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.23919/eusipco.2018.8553142" target="_blank">DOI</a>]
  
  
  
  
    [<a href="/assets/pdf/../../pdf/conferences/elvira2018eusipco.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01961852" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://github.com/c-elvira/IBPDL-SVA" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2018eusipco,
  doi = {10.23919/eusipco.2018.8553142},
  year = {2018},
  month = sep,
  publisher = {{IEEE}},
  author = {Elvira, Clement and Dang, Hong-Phuong and Chainais, Pierre},
  title = {Small variance asymptotics and bayesian nonparametrics for dictionary learning},
  booktitle = {2018 26th European Signal Processing Conference ({EUSIPCO})},
  pdf = {../../pdf/conferences/elvira2018eusipco.pdf},
  code = {https://github.com/c-elvira/IBPDL-SVA},
  hal = {https://hal.archives-ouvertes.fr/hal-01961852}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Bayesian nonparametric (BNP) is an appealing framework to infer the complexity of a model along with the parameters. To this aim, sampling or variational methods are often used for inference. However, these methods come with numerical disadvantages for large-scale data. An alternative approach is to relax the probabilistic model into a non-probabilistic formulation which yields a scalable algorithm. One limitation of BNP approaches can be the cost of Monte-Carlo sampling for inference. Small-variance asymptotic (SVA) approaches paves the way to much cheaper though approximate methods for inference by taking benefit from a fruitful interaction between Bayesian models and optimization algorithms. In brief, SVA lets the variance of the noise (or residual error) distribution tend to zero in the optimization problem corresponding to a MAP estimator with finite noise variance for instance. We propose such an SVA analysis of a BNP dictionary learning (DL) approach that automatically adapts the size of the dictionary or the subspace dimension in an efficient way. Numerical experiments illustrate the efficiency of the proposed method.</p>
  </span>
  
</div>
</li>
<li>

<div id="Elvira_IEEE_ICASSP_2017">
  
    <span class="title">Bayesian nonparametric subspace estimation</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://dobigeon.perso.enseeiht.fr/" target="_blank">Dobigeon, Nicolas</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>
    
    
      2017
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1109/ICASSP.2017.7952556" target="_blank">DOI</a>]
  
  
  
  
    [<a href="/assets/pdf/../../pdf/conferences/elvira2017iccasp.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01687163" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{Elvira_IEEE_ICASSP_2017,
  author = {Elvira, Clément and Chainais, Pierre and Dobigeon, Nicolas},
  booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  doi = {10.1109/ICASSP.2017.7952556},
  keywords = {Bayes methods;Estimation;Manifolds;Monte Carlo methods;Numerical models;Principal component analysis;Probabilistic logic;Bayesian inference;Indian buffet process;dimension reduction;distribution on the Stiefel manifold},
  month = mar,
  pages = {2247-2251},
  title = {Bayesian nonparametric subspace estimation},
  year = {2017},
  pdf = {../../pdf/conferences/elvira2017iccasp.pdf},
  hal = {https://hal.archives-ouvertes.fr/hal-01687163}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Principal component analysis is a widely used technique to perform dimension reduction. However, selecting a finite number of significant components is essential and remains a crucial issue. Only few attempts have proposed a probabilistic approach to adaptively select this number. This paper introduces a Bayesian nonparametric model to jointly estimate the principal components and the corresponding intrinsic dimension. More precisely, the observations are projected onto a random orthogonal basis which is assigned a prior distribution defined on the Stiefel manifold. Then the factor scores take benefit of an Indian buffet process prior to model the uncertainty related to the number of components. The parameters of interest as well as the nuisance parameters are finally inferred within a fully Bayesian framework via Monte Carlo sampling. The performances of the proposed approach are assessed thanks to experiments conducted on various examples.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2016ssp">
  
    <span class="title">Democratic prior for anti-sparse coding</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://dobigeon.perso.enseeiht.fr/" target="_blank">Dobigeon, Nicolas</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2016 IEEE Statistical Signal Processing Workshop (SSP)</em>
    
    
      2016
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
    [<a href="https://doi.org\10.1109/SSP.2016.7551813" target="_blank">DOI</a>]
  
  
  
  
    [<a href="/assets/pdf/../../pdf/conferences/elvira2016ssp.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01433632" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://github.com/c-elvira/bayesian_antisparse_algorithm" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2016ssp,
  author = {Elvira, Clément and Chainais, Pierre and Dobigeon, Nicolas},
  booktitle = {2016 IEEE Statistical Signal Processing Workshop (SSP)},
  title = {Democratic prior for anti-sparse coding},
  year = {2016},
  pages = {1-4},
  keywords = {Markov processes;Monte Carlo methods;inverse problems;probability;signal representation;ℓ∞-norm regularization;Gibbs sampler;anti-sparse coding;complete dictionary;democratic distribution;joint posterior distribution;linear Gaussian inverse problem;probabilistic formulation;probability distribution;proximal Markov chain Monte Carlo algorithm;representation coefficients;Bayes methods;Encoding;Inverse problems;Monte Carlo methods;Peak to average power ratio;Probability density function;Signal processing algorithms;Anti-sparse representation;democratic distribution;inverse problem},
  doi = {10.1109/SSP.2016.7551813},
  month = jun,
  pdf = {../../pdf/conferences/elvira2016ssp.pdf},
  code = {https://github.com/c-elvira/bayesian_antisparse_algorithm},
  hal = {https://hal.archives-ouvertes.fr/hal-01433632}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Bayesian nonparametric (BNP) is an appealing framework to infer the complexity of a model along with the parameters. To this aim, sampling or variational methods are often used for inference. However, these methods come with numerical disadvantages for large-scale data. An alternative approach is to relax the probabilistic model into a non-probabilistic formulation which yields a scalable algorithm. One limitation of BNP approaches can be the cost of Monte-Carlo sampling for inference. Small-variance asymptotic (SVA) approaches paves the way to much cheaper though approximate methods for inference by taking benefit from a fruitful interaction between Bayesian models and optimization algorithms. In brief, SVA lets the variance of the noise (or residual error) distribution tend to zero in the optimization problem corresponding to a MAP estimator with finite noise variance for instance. We propose such an SVA analysis of a BNP dictionary learning (DL) approach that automatically adapts the size of the dictionary or the subspace dimension in an efficient way. Numerical experiments illustrate the efficiency of the proposed method.</p>
  </span>
  
</div>
</li></ol>

<h4 id="national-conference-papers">National conference papers</h4>
<ol class="bibliography"><li>

<div id="elvira2019gretsi">
  
    <span class="title">Identification de supports en k etapes avec OMP pour les dictionnaires continus</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://people.irisa.fr/Remi.Gribonval/" target="_blank">Gribonval, Rémi</a>, 
              
            
          
        
      
        
          
            
              
                <a href="http://webpages.lss.supelec.fr/perso/charles.soussen/soussen_EN.html" target="_blank">Soussen, Charles</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In GRETSI 2019 - XXVIIème Colloque francophonede traitement du signal et des images</em>
    
    
      2019
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
    [<a href="https://hal.inria.fr/hal-02157571v1" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2019gretsi,
  title = {{Identification de supports en k etapes avec OMP pour les dictionnaires continus}},
  author = {Elvira, Cl{\'e}ment and Gribonval, R{\'e}mi and Soussen, Charles and Herzet, C{\'e}dric},
  url = {https://hal.inria.fr/hal-02157571},
  booktitle = {{GRETSI 2019 - XXVII{\`e}me Colloque francophonede traitement du signal et des images}},
  address = {Lille, France},
  pages = {1-4},
  year = {2019},
  month = aug,
  language = {French},
  hal = {https://hal.inria.fr/hal-02157571v1}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Nous présentons de nouveaux résultats concernant les garanties d’identification de support en k étapes pour un algorithme glouton, orthogonal matching pursuit (OMP), pour les dictionnaires continus. Un dictionnaire est dit continu s’il est constitué d’une infinité indénom-brable d’atomes. Nous étudions une famille de dictionnaires paramétrés, appelée CMF (pour completely monotone function), pour laquelle l’identification de support en k étapes est toujours possible lorsque le paramètre est de dimension 1 quels que soient le nombre et le choix des atomes du support. En dimension supérieure, des conditions algébriques deviennent nécessaires et nous amènent à revisiter les analyses classiques du cas discret. Finalement, nous discutons l’implémentation d’une version continue d’OMP.</p>
  </span>
  
</div>
</li>
<li>

<div id="dang2018cap">
  
    <span class="title"> Vers une méthode d’optimisation non paramétrique pour l’apprentissage de dictionnaire en utilisant Small-Variance Asymptotics pour modèle probabiliste</span>
    <span class="author">
      
        
          
            
              
                <a href="https://hphuongdang.github.io/" target="_blank">Dang, Hong-Phuong</a>, 
              
            
          
        
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                and <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In CAP</em>
    
    
      2018
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/natConf/dang2018cap.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://github.com/c-elvira/IBPDL-SVA" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{dang2018cap,
  author = {Dang, Hong-Phuong and Elvira, Clément and Chainais, Pierre},
  title = { Vers une méthode d'optimisation non paramétrique pour l'apprentissage de dictionnaire en utilisant Small-Variance Asymptotics pour modèle probabiliste},
  booktitle = {CAP},
  year = {2018},
  address = {Rouen},
  language = {French},
  pdf = {../../pdf/natConf/dang2018cap.pdf},
  code = {https://github.com/c-elvira/IBPDL-SVA}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Dans les modèles probabilistes, les méthodes d’échantillonnage   et les approximations variationnelles sont souvent utilisées pour l’inférence. Mais ces méthodes passent difficilement à l’échelle. Une  alternative consiste à relâcher le modèle probabiliste dans une formulation  non probabiliste et utiliser un algorithme évolutif pour résoudre le problème de minimisation associé. Nous proposons une analyse dite de Small-Variance  Asymptotics (SVA) du modèle bayésien non paramétrique de type Buffet Indien à deux paramètres qui apprend automatiquement un dictionnaire de taille adaptée. Cette  approche s’obtient en faisant tendre la variance de la  vraisemblance du modèle vers 0. L’analyse montre une interaction entre les méthodes bayésiennes et optimisation. Les résultats illustrent la pertinence de la méthode proposée.</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2017gretsi">
  
    <span class="title">Une formulation bayésienne du codage antiparcimonieux</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="http://pierrechainais.ec-lille.fr/" target="_blank">Chainais, Pierre</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="http://dobigeon.perso.enseeiht.fr/" target="_blank">Dobigeon, Nicolas</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Actes du XXVIi‘eme Colloque GRETSI</em>
    
    
      2017
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/natConf/elvira2017gretsi.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-01691387" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://github.com/c-elvira/bayesian_antisparse_algorithm" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@inproceedings{elvira2017gretsi,
  author = {Elvira, Clément and Chainais, Pierre and Dobigeon, Nicolas},
  title = {Une formulation bayésienne du codage antiparcimonieux},
  booktitle = {Actes du XXVIi`eme Colloque GRETSI},
  year = {2017},
  address = {Juan-les-Pins, France},
  language = {French},
  pdf = {../../pdf/natConf/elvira2017gretsi.pdf},
  code = {https://github.com/c-elvira/bayesian_antisparse_algorithm},
  hal = {https://hal.archives-ouvertes.fr/hal-01691387}
}
</p>
  </span>
  
  <span class="abstract hidden">
    <p>Dans un but de robustesse, un codage antiparcimonieux répartit uniformément l’information d’un signal sur toutes les composantes de sa représentation. La recherche d’un tel codage s’exprime naturellement sous la forme d’un problème variationnel impliquant une régularisation de type \ell_∞. Dans cet article une formulation bayésienne du problème est proposée, impliquant une nouvelle loi de probabilité, la loi démocratique, qui pénalise les fortes amplitudes. Cette distribution est choisie comme loi a priori sur les coefficients de représentation, couplée avec une vraisemblance gaussienne. Les estimateurs bayésiens des coefficients de représentation peuvent être approchés à l’aide d’un échantillonneur de Gibbs. Cette méthode passe cependant difficilement à l’échelle et un algorithme de Monte Carlo proximal a été proposé. On discute une nouvelle façon de choisir et régler la loi a priori sur les paramètres de nuisance. Deux simulations numériques permettent de valider le réglage des hyperparamètres et la recherche du paramètre de régularisation.</p>
  </span>
  
</div>
</li></ol>

<h4 id="technical-reports">Technical reports</h4>
<ol class="bibliography"><li>

<div id="Le2022HolderDomeTechreport">
  
    <span class="title">Beyond GAP screening for Lasso  by exploiting new dual cutting half-spaces with supplementary material</span>
    <span class="author">
      
        
          
            
              
                <a href="https://tranthule.blogspot.com/p/about-me.html" target="_blank">Tran, Thu-Le</a>, 
              
            
          
        
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                <a href="https://hphuongdang.github.io/" target="_blank">Dang, Hong-Phuong</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2022
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
    [<a href="http://arxiv.org/abs/2203.00987" target="_blank">arXiv</a>]
  
  
  
    [<a href="/assets/pdf/../../pdf/tecreports/Le2022TR.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://gitlab.inria.fr/cherzet/holder-safe" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@techreport{Le2022HolderDomeTechreport,
  author = {Tran, Thu-Le and Elvira, Cl{\'e}ment and Dang, Hong-Phuong and Herzet, C{\'e}dric},
  pdf = {../../pdf/tecreports/Le2022TR.pdf},
  title = {Beyond {GAP} screening for {Lasso}  by exploiting new dual cutting half-spaces with supplementary material},
  year = {2022},
  code = {https://gitlab.inria.fr/cherzet/holder-safe},
  month = feb,
  arxiv = {2203.00987}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="elvira2021safeSLOPEsuppmat">
  
    <span class="title">Supplementary materials: Safe rules for the identification of zeros in the solutions of the SLOPE problem</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2021slope/elvira2021SLOPEsuppmat.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@techreport{elvira2021safeSLOPEsuppmat,
  title = {{Supplementary materials: Safe rules for the identification of zeros in the solutions of the SLOPE problem}},
  author = {Elvira, Clément and Herzet, Cédric},
  year = {2021},
  month = oct,
  pdf = {../../pdf/articles/elvira2021slope/elvira2021SLOPEsuppmat.pdf}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="Elvira2021techreport">
  
    <span class="title">A response to “Fast OSCAR and OWL Regression via Safe Screening Rules” by Bao et al.</span>
    <span class="author">
      
        
          
            
              <em>Elvira, Clément</em>,
            
          
        
      
        
          
            
              
                and <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/tecreports/Elvira2021_responseSLOPE.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@techreport{Elvira2021techreport,
  author = {Elvira, Clément and Herzet, Cédric},
  note = {Technical report},
  title = {A response to ``Fast OSCAR and OWL Regression via Safe Screening Rules'' by Bao et al.},
  institution = {},
  month = oct,
  pdf = {../../pdf/tecreports/Elvira2021_responseSLOPE.pdf},
  year = {2021}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="guyard2021screen">
  
    <span class="title">Screen &amp; Relax: Accelerating the resolution of Elastic-net by safe identification of the solution support</span>
    <span class="author">
      
        
          
            
              
                <a href="https://theoguyard.github.io" target="_blank">Guyard, Théo</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a>, 
              
            
          
        
      
        
          
            
              and <em>Elvira, Clément</em>
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
    [<a href="http://arxiv.org/abs/2110.07281" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03462191v1" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://gitlab.insa-rennes.fr/Theo.Guyard/screen-and-relax" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@techreport{guyard2021screen,
  title = {Screen \&amp; Relax: Accelerating the resolution of Elastic-net by safe identification of the solution support},
  author = {Guyard, Th{\'e}o and Herzet, C{\'e}dric and Elvira, Cl{\'e}ment},
  arxiv = {2110.07281},
  year = {2021},
  code = {https://gitlab.insa-rennes.fr/Theo.Guyard/screen-and-relax},
  hal = {https://hal.archives-ouvertes.fr/hal-03462191v1}
}
</p>
  </span>
  
</div>
</li>
<li>

<div id="Guyard2021techreport">
  
    <span class="title">Node-screening tests for l0-penalized Least-Squares problem with supplementary material</span>
    <span class="author">
      
        
          
            
              
                <a href="https://theoguyard.github.io" target="_blank">Guyard, Théo</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Main.html" target="_blank">Herzet, Cédric</a>, 
              
            
          
        
      
        
          
            
              and <em>Elvira, Clément</em>
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
    [<a href="http://arxiv.org/abs/2110.07308" target="_blank">arXiv</a>]
  
  
  
    [<a href="/assets/pdf/../../pdf/tecreports/Guyard2021_l0.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://hal.archives-ouvertes.fr/hal-03462171" target="_blank">HAL</a>]
  
  
  
  
  
    [<a href="https://gitlab.insa-rennes.fr/Theo.Guyard/bnb-screening" target="_blank">Code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@techreport{Guyard2021techreport,
  author = {Guyard, Théo and Herzet, Cédric and Elvira, Clément},
  keywords = {Branch-and-bound ; Cardinality constraint ; Sparse approximation ; Continuous relaxation ; Homotopy continuation},
  note = {Technical report},
  title = {Node-screening tests for l0-penalized Least-Squares problem with supplementary material},
  institution = {Insa Rennes},
  month = oct,
  pdf = {../../pdf/tecreports/Guyard2021_l0.pdf},
  code = {https://gitlab.insa-rennes.fr/Theo.Guyard/bnb-screening},
  year = {2021},
  arxiv = {2110.07308},
  hal = {https://hal.archives-ouvertes.fr/hal-03462171}
}
</p>
  </span>
  
</div>
</li></ol>

<h4 id="thesis">Thesis</h4>
<ol class="bibliography"><li>

<div id="elvira2017phdthesis">
  
    <span class="title">Modèles bayésiens pour l’identification de représentations antiparcimonieuses et l’analyse en composantes principales non paramétrique</span>
    <span class="author">
      
        
          
            <em>Elvira, Clément</em>
          
        
      
    </span>

    <span class="periodical">
    
    
      2017
    
    </span>
  


  <span class="links">
    [<a class="bibtex">Bibtex</a>]
  
  
  
  
  
  
    [<a href="/assets/pdf/../../pdf/articles/elvira2017manuscritthese.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://tel.archives-ouvertes.fr/tel-01730077v2" target="_blank">HAL</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  <span class="bibtex hidden">
    <p>@phdthesis{elvira2017phdthesis,
  author = {Elvira, Clément},
  title = {Modèles bayésiens pour l’identification de représentations antiparcimonieuses et l’analyse en composantes principales non paramétrique},
  language = {French},
  year = {2017},
  month = nov,
  school = {Centrale Lille},
  address = {Lille, France},
  pdf = {../../pdf/articles/elvira2017manuscritthese.pdf},
  hal = {https://tel.archives-ouvertes.fr/tel-01730077v2}
}
</p>
  </span>
  
</div>
</li></ol>

  </article>

  

  

</div>

      </div>
    </div>

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
